{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5b3ba8",
   "metadata": {},
   "source": [
    "# Data Cleaning & Feature Engineering\n",
    "\n",
    "This notebook transforms the raw scraped data into a clean, model-ready dataset through systematic cleaning and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c7788",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "003e7edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset: 949 rows, 9 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>House_Size</th>\n",
       "      <th>Land_Size</th>\n",
       "      <th>Description</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ikman.lk/en/ad/swimming-pool-with-luxu...</td>\n",
       "      <td>69000000</td>\n",
       "      <td>Kesbewa</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2,800.0 sqft</td>\n",
       "      <td>20.0 perches</td>\n",
       "      <td>‚ú≥Ô∏è Brand New Super Luxury Modern Villa‚Äôs For S...</td>\n",
       "      <td>Kesbewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://ikman.lk/en/ad/modern-house-for-sale-i...</td>\n",
       "      <td>200000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9,000.0 sqft</td>\n",
       "      <td>20.0 perches</td>\n",
       "      <td>luxury New House for sale in Thalawathugoda‚Ç¨12...</td>\n",
       "      <td>Thalawathugoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ikman.lk/en/ad/luxury-house-for-sale-i...</td>\n",
       "      <td>39000000</td>\n",
       "      <td>Kesbewa</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2,680.0 sqft</td>\n",
       "      <td>6.2 perches</td>\n",
       "      <td>‚úÖ ‡∂¥‡∑í‡∂Ω‡∑í‡∂∫‡∂±‡∑ä‡∂Ø‡∂Ω ‡∂ß‡∑Ä‡∑î‡∂∏‡∂ß ‡∂±‡∑î‡∂Ø‡∑î‡∂ª‡∑î‡∑Ä, ‡∂ö‡∑ê‡∑É‡∑ä‡∂∂‡∑ê‡∑Ä ‡∑Ñ‡∂Ç‡∂Ø‡∑í‡∂∫‡∂ß ‡∂á‡∑Ä‡∑í‡∂Ø...</td>\n",
       "      <td>Kesbewa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://ikman.lk/en/ad/kaduwela-nawagamuwa-two...</td>\n",
       "      <td>19000000</td>\n",
       "      <td>Kaduwela&nbsp;&nbsp;Nawagamuwa</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2,280.0 sqft</td>\n",
       "      <td>10.5 perches</td>\n",
       "      <td>TWO STORY HOUSE FOR SALE IN KADUWELA&nbsp;&nbsp;NAWAGAMU...</td>\n",
       "      <td>Kaduwela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://ikman.lk/en/ad/single-storied-best-hou...</td>\n",
       "      <td>22000000</td>\n",
       "      <td>Galwarusawa Rd, Athurugiriya</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1,366.0 sqft</td>\n",
       "      <td>8.15 perches</td>\n",
       "      <td>Single Storied&nbsp;&nbsp;House For Sale Galwarusawa Roa...</td>\n",
       "      <td>Athurugiriya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL      Price  \\\n",
       "0  https://ikman.lk/en/ad/swimming-pool-with-luxu...   69000000   \n",
       "1  https://ikman.lk/en/ad/modern-house-for-sale-i...  200000000   \n",
       "2  https://ikman.lk/en/ad/luxury-house-for-sale-i...   39000000   \n",
       "3  https://ikman.lk/en/ad/kaduwela-nawagamuwa-two...   19000000   \n",
       "4  https://ikman.lk/en/ad/single-storied-best-hou...   22000000   \n",
       "\n",
       "                        Address Bedrooms Bathrooms    House_Size  \\\n",
       "0                       Kesbewa        5         5  2,800.0 sqft   \n",
       "1                           NaN        9         8  9,000.0 sqft   \n",
       "2                       Kesbewa        4         4  2,680.0 sqft   \n",
       "3          Kaduwela  Nawagamuwa        4         2  2,280.0 sqft   \n",
       "4  Galwarusawa Rd, Athurugiriya        3         2  1,366.0 sqft   \n",
       "\n",
       "      Land_Size                                        Description  \\\n",
       "0  20.0 perches  ‚ú≥Ô∏è Brand New Super Luxury Modern Villa‚Äôs For S...   \n",
       "1  20.0 perches  luxury New House for sale in Thalawathugoda‚Ç¨12...   \n",
       "2   6.2 perches  ‚úÖ ‡∂¥‡∑í‡∂Ω‡∑í‡∂∫‡∂±‡∑ä‡∂Ø‡∂Ω ‡∂ß‡∑Ä‡∑î‡∂∏‡∂ß ‡∂±‡∑î‡∂Ø‡∑î‡∂ª‡∑î‡∑Ä, ‡∂ö‡∑ê‡∑É‡∑ä‡∂∂‡∑ê‡∑Ä ‡∑Ñ‡∂Ç‡∂Ø‡∑í‡∂∫‡∂ß ‡∂á‡∑Ä‡∑í‡∂Ø...   \n",
       "3  10.5 perches  TWO STORY HOUSE FOR SALE IN KADUWELA  NAWAGAMU...   \n",
       "4  8.15 perches  Single Storied  House For Sale Galwarusawa Roa...   \n",
       "\n",
       "             City  \n",
       "0         Kesbewa  \n",
       "1  Thalawathugoda  \n",
       "2         Kesbewa  \n",
       "3        Kaduwela  \n",
       "4    Athurugiriya  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../data/02_intermediate/house_data_with_city.csv')\n",
    "print(f\"Initial dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a908504",
   "metadata": {},
   "source": [
    "## Data Quality Assessment\n",
    "\n",
    "Analyze missing values and data completeness before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b593ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Analysis:\n",
      "==================================================\n",
      " Column  Missing_Count  Missing_Percent\n",
      "Address             77             8.11\n",
      "\n",
      "Total missing cells: 77\n",
      "Data completeness: 99.10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing Values Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percent': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"No missing values detected!\")\n",
    "\n",
    "print(f\"\\nTotal missing cells: {df.isnull().sum().sum()}\")\n",
    "print(f\"Data completeness: {(1 - df.isnull().sum().sum()/(df.shape[0]*df.shape[1]))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dadb7d7",
   "metadata": {},
   "source": [
    "## Step 1: Clean House_Size & Land_Size\n",
    "\n",
    "Strip units, commas, and convert to numeric values for model compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c40b39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House_Size - Non-null: 949, Mean: 3027.20\n",
      "Land_Size - Non-null: 949, Mean: 12.58\n"
     ]
    }
   ],
   "source": [
    "def clean_size(value):\n",
    "    \"\"\"Extract numeric value from size strings\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    value_str = str(value)\n",
    "    value_str = re.sub(r'[^\\d.]', '', value_str)\n",
    "    try:\n",
    "        return float(value_str) if value_str else np.nan\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df['House_Size'] = df['House_Size'].apply(clean_size)\n",
    "df['Land_Size'] = df['Land_Size'].apply(clean_size)\n",
    "\n",
    "print(f\"House_Size - Non-null: {df['House_Size'].notna().sum()}, Mean: {df['House_Size'].mean():.2f}\")\n",
    "print(f\"Land_Size - Non-null: {df['Land_Size'].notna().sum()}, Mean: {df['Land_Size'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdfe7e",
   "metadata": {},
   "source": [
    "## Step 1b: Outlier Detection & Handling\n",
    "\n",
    "Remove extreme outliers using IQR method to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b27743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House_Size:\n",
      "  Range: [0.00, 8000.00]\n",
      "  Removed: 18 outliers (1.90%)\n",
      "Land_Size:\n",
      "  Range: [0.00, 34.20]\n",
      "  Removed: 23 outliers (2.47%)\n",
      "\n",
      "Total rows removed: 41 (4.32%)\n",
      "Remaining rows: 908\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_iqr(df, column, multiplier=3.0):\n",
    "    \"\"\"Remove outliers using IQR method with adjustable sensitivity\"\"\"\n",
    "    if df[column].notna().sum() == 0:\n",
    "        return df\n",
    "    \n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    # Keep lower bound at 0 for sizes (can't be negative)\n",
    "    lower_bound = max(0, lower_bound)\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)) & df[column].notna()\n",
    "    df_filtered = df[~outliers].copy()\n",
    "    removed = initial_count - len(df_filtered)\n",
    "    \n",
    "    print(f\"{column}:\")\n",
    "    print(f\"  Range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(f\"  Removed: {removed} outliers ({removed/initial_count*100:.2f}%)\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "initial_size = len(df)\n",
    "\n",
    "# Remove outliers from size columns\n",
    "df = remove_outliers_iqr(df, 'House_Size', multiplier=3.0)\n",
    "df = remove_outliers_iqr(df, 'Land_Size', multiplier=3.0)\n",
    "\n",
    "total_removed = initial_size - len(df)\n",
    "print(f\"\\nTotal rows removed: {total_removed} ({total_removed/initial_size*100:.2f}%)\")\n",
    "print(f\"Remaining rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8b1f7",
   "metadata": {},
   "source": [
    "## Step 2: Logic Check & Filtering\n",
    "\n",
    "Remove invalid entries to prevent model confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dc185aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with missing critical values:\n",
      "  Rows with NaN in critical columns: 2\n",
      "\n",
      "Applying logical filters:\n",
      "  Bedrooms = 0: 0\n",
      "  Bathrooms = 0: 0\n",
      "  Unrealistic bedroom/bathroom counts (>15): 0\n",
      "  Price outliers: 0\n",
      "\n",
      "==================================================\n",
      "Total removed: 2 rows (0.2%)\n",
      "Remaining: 906 rows\n",
      "Price range: LKR 1,500,000 - LKR 850,000,000\n",
      "Bedrooms range: 2 - 10\n",
      "Bathrooms range: 1 - 6\n"
     ]
    }
   ],
   "source": [
    "initial_count = len(df)\n",
    "\n",
    "# Convert to numeric\n",
    "df['Bedrooms'] = pd.to_numeric(df['Bedrooms'], errors='coerce')\n",
    "df['Bathrooms'] = pd.to_numeric(df['Bathrooms'], errors='coerce')\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "# Remove rows with critical missing values\n",
    "print(\"Removing rows with missing critical values:\")\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['Bedrooms', 'Bathrooms', 'Price'])\n",
    "print(f\"  Rows with NaN in critical columns: {before - len(df)}\")\n",
    "\n",
    "# Apply logical filters\n",
    "print(\"\\nApplying logical filters:\")\n",
    "before = len(df)\n",
    "df = df[df['Bedrooms'] > 0]\n",
    "print(f\"  Bedrooms = 0: {before - len(df)}\")\n",
    "\n",
    "before = len(df)\n",
    "df = df[df['Bathrooms'] > 0]\n",
    "print(f\"  Bathrooms = 0: {before - len(df)}\")\n",
    "\n",
    "before = len(df)\n",
    "df = df[(df['Bedrooms'] <= 15) & (df['Bathrooms'] <= 15)]\n",
    "print(f\"  Unrealistic bedroom/bathroom counts (>15): {before - len(df)}\")\n",
    "\n",
    "before = len(df)\n",
    "df = df[(df['Price'] >= 1_000_000) & (df['Price'] <= 2_000_000_000)]\n",
    "print(f\"  Price outliers: {before - len(df)}\")\n",
    "\n",
    "removed_count = initial_count - len(df)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total removed: {removed_count} rows ({removed_count/initial_count*100:.1f}%)\")\n",
    "print(f\"Remaining: {len(df)} rows\")\n",
    "print(f\"Price range: LKR {df['Price'].min():,.0f} - LKR {df['Price'].max():,.0f}\")\n",
    "print(f\"Bedrooms range: {df['Bedrooms'].min():.0f} - {df['Bedrooms'].max():.0f}\")\n",
    "print(f\"Bathrooms range: {df['Bathrooms'].min():.0f} - {df['Bathrooms'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e6898e",
   "metadata": {},
   "source": [
    "## Step 3: Feature Engineering - Text Extraction\n",
    "\n",
    "Extract valuable signals from property descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60ae3447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand New: 181 (20.0%)\n",
      "Modern/Luxury: 377 (41.6%)\n"
     ]
    }
   ],
   "source": [
    "def extract_binary_features(description):\n",
    "    \"\"\"Extract key property attributes from text\"\"\"\n",
    "    if pd.isna(description):\n",
    "        return 0, 0\n",
    "    \n",
    "    desc_lower = str(description).lower()\n",
    "    \n",
    "    is_brand_new = 1 if any(keyword in desc_lower for keyword in ['brand new', 'newly built', 'new house']) else 0\n",
    "    is_modern = 1 if any(keyword in desc_lower for keyword in ['modern', 'luxury', 'contemporary']) else 0\n",
    "    \n",
    "    return is_brand_new, is_modern\n",
    "\n",
    "df[['Is_Brand_New', 'Is_Modern']] = df['Description'].apply(\n",
    "    lambda x: pd.Series(extract_binary_features(x))\n",
    ")\n",
    "\n",
    "print(f\"Brand New: {df['Is_Brand_New'].sum()} ({df['Is_Brand_New'].mean()*100:.1f}%)\")\n",
    "print(f\"Modern/Luxury: {df['Is_Modern'].sum()} ({df['Is_Modern'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d7efac",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering - City Tiering\n",
    "\n",
    "Group cities by median price to solve the high-cardinality problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9227ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique cities: 57\n",
      "\n",
      "Top 10 most expensive cities:\n",
      "City\n",
      "Colombo 4     300000000.0\n",
      "Colombo 7     235000000.0\n",
      "Nawala        133000000.0\n",
      "Kohuwala      132500000.0\n",
      "Kotte         126000000.0\n",
      "Colombo 1     118000000.0\n",
      "Dehiwala      115000000.0\n",
      "Kalubowila     97500000.0\n",
      "Colombo 3      97000000.0\n",
      "Colombo 2      95500000.0\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "city_median_prices = df.groupby('City')['Price'].median().sort_values(ascending=False)\n",
    "print(f\"Total unique cities: {len(city_median_prices)}\")\n",
    "print(f\"\\nTop 10 most expensive cities:\")\n",
    "print(city_median_prices.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff1b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City distribution across tiers:\n",
      "  Tier 1 (Luxury): 10 cities, 92 properties, Median: LKR 125,000,000\n",
      "    Cities: Colombo 1, Colombo 2, Colombo 3, Colombo 4, Colombo 7, Dehiwala, Kalubowila, Kohuwala, Kotte, Nawala\n",
      "  Tier 2 (Premium): 9 cities, 166 properties, Median: LKR 74,750,000\n",
      "    Cities: Battaramulla, Borella, Colombo 5, Colombo 6, Mount Lavinia, Nugegoda, Pelawatte, Rajagiriya, Ratmalana\n",
      "  Tier 3 (Upper-Mid): 9 cities, 151 properties, Median: LKR 59,000,000\n",
      "    Cities: Angoda, Avissawella, Boralesgamuwa, Colombo 10, Hokandara, Moratuwa, Pannipitiya, Talawatugoda, Thalawathugoda\n",
      "  Tier 4 (Mid-Range): 10 cities, 233 properties, Median: LKR 39,000,000\n",
      "    Cities: Bokundara, Colombo 13, Colombo 15, Dematagoda, Kesbewa, Madapatha, Maharagama, Malabe, Pettah, Piliyandala\n",
      "  Tier 5 (Affordable): 9 cities, 203 properties, Median: LKR 29,500,000\n",
      "    Cities: Athurugiriya, Colombo 12, Diyagama, Fort, Kahathuduwa, Kolonnawa, Kottawa, Mattegoda, Polgasowita\n",
      "  Tier 6 (Budget): 10 cities, 61 properties, Median: LKR 19,000,000\n",
      "    Cities: Colombo 11, Colombo 14, Godagama, Homagama, Kaduwela, Maradana, Mattakkuliya, Meegoda, Padukka, Wellampitiya\n"
     ]
    }
   ],
   "source": [
    "n_tiers = 6\n",
    "city_median_prices = df.groupby('City')['Price'].median().sort_values(ascending=False)\n",
    "\n",
    "# Tier 1 = Luxury (highest price), Tier 6 = Budget (lowest price)\n",
    "tier_labels = {1: 'Luxury', 2: 'Premium', 3: 'Upper-Mid', 4: 'Mid-Range', 5: 'Affordable', 6: 'Budget'}\n",
    "\n",
    "city_tiers = pd.qcut(city_median_prices, q=n_tiers, labels=range(n_tiers, 0, -1), duplicates='drop')\n",
    "city_tier_map = city_tiers.to_dict()\n",
    "\n",
    "df['City_Tier'] = df['City'].map(city_tier_map)\n",
    "\n",
    "print(f\"City distribution across tiers:\")\n",
    "for tier in range(1, n_tiers+1):\n",
    "    tier_cities = [city for city, t in city_tier_map.items() if t == tier]\n",
    "    tier_count = (df['City_Tier'] == tier).sum()\n",
    "    cities_list = ', '.join(sorted(tier_cities))\n",
    "    tier_median = df[df['City'].isin(tier_cities)]['Price'].median()\n",
    "    print(f\"  Tier {tier} ({tier_labels[tier]}): {len(tier_cities)} cities, {tier_count} properties, Median: LKR {tier_median:,.0f}\")\n",
    "    print(f\"    Cities: {cities_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6821ab",
   "metadata": {},
   "source": [
    "## Step 5: Encoding\n",
    "\n",
    "Apply label encoding to preserve ordinal relationship in city tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dc4c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City_Tier encoding complete\n",
      "Value range: 1 to 6\n",
      "\n",
      "City Tier vs Median Price:\n",
      "City_Tier\n",
      "1    125000000.0\n",
      "2     74750000.0\n",
      "3     59000000.0\n",
      "4     39000000.0\n",
      "5     29500000.0\n",
      "6     19000000.0\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['City_Tier'] = df['City_Tier'].astype(int)\n",
    "\n",
    "print(f\"City_Tier encoding complete\")\n",
    "print(f\"Value range: {df['City_Tier'].min()} to {df['City_Tier'].max()}\")\n",
    "print(f\"\\nCity Tier vs Median Price:\")\n",
    "print(df.groupby('City_Tier')['Price'].median().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2ed23",
   "metadata": {},
   "source": [
    "## Step 5b: Train-Test Split\n",
    "\n",
    "Split data before scaling to prevent data leakage. Scaler should only learn from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cf9b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 724 samples (79.9%)\n",
      "Test set: 182 samples (20.1%)\n",
      "\n",
      "Training set price range: LKR 1,500,000 - LKR 850,000,000\n",
      "Test set price range: LKR 10,500,000 - LKR 270,000,000\n",
      "\n",
      "City Tier distribution:\n",
      "Train set:\n",
      "City_Tier\n",
      "1     73\n",
      "2    133\n",
      "3    121\n",
      "4    186\n",
      "5    162\n",
      "6     49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set:\n",
      "City_Tier\n",
      "1    19\n",
      "2    33\n",
      "3    30\n",
      "4    47\n",
      "5    41\n",
      "6    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create target variable before split\n",
    "df['Price_Log'] = np.log(df['Price'])\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = ['Bedrooms', 'Bathrooms', 'House_Size', 'Land_Size', 'Is_Brand_New', 'Is_Modern', 'City_Tier']\n",
    "X = df[feature_cols].copy()\n",
    "y = df['Price_Log'].copy()\n",
    "\n",
    "# Split into train and test sets (80-20 split, stratified by City_Tier)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=df['City_Tier']\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTraining set price range: LKR {np.exp(y_train.min()):,.0f} - LKR {np.exp(y_train.max()):,.0f}\")\n",
    "print(f\"Test set price range: LKR {np.exp(y_test.min()):,.0f} - LKR {np.exp(y_test.max()):,.0f}\")\n",
    "\n",
    "# City tier distribution in train/test\n",
    "print(f\"\\nCity Tier distribution:\")\n",
    "print(\"Train set:\")\n",
    "print(X_train['City_Tier'].value_counts().sort_index())\n",
    "print(\"\\nTest set:\")\n",
    "print(X_test['City_Tier'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c180ccc7",
   "metadata": {},
   "source": [
    "## Step 6: Scaling & Normalization\n",
    "\n",
    "Transform distributions using training data only to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51433699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed missing House_Size with: 2800.00\n",
      "Imputed missing Land_Size with: 9.60\n",
      "\n",
      "Scaled features: ['Bedrooms', 'Bathrooms', 'House_Size', 'Land_Size']\n",
      "\n",
      "Training set statistics (after scaling):\n",
      "  Bedrooms: Mean=0.00, Std=1.00\n",
      "  Bathrooms: Mean=-0.00, Std=1.00\n",
      "  House_Size: Mean=-0.00, Std=1.00\n",
      "  Land_Size: Mean=0.00, Std=1.00\n",
      "\n",
      "Test set statistics (after scaling):\n",
      "  Bedrooms: Mean=-0.07, Std=0.92\n",
      "  Bathrooms: Mean=-0.05, Std=0.91\n",
      "  House_Size: Mean=-0.12, Std=0.86\n",
      "  Land_Size: Mean=0.01, Std=1.06\n",
      "\n",
      "Target variable (Price_Log) statistics:\n",
      "  Training: Mean=17.69, Std=0.70, Skewness=0.44\n",
      "  Test: Mean=17.65, Std=0.64, Skewness=0.41\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values in size columns (impute with training median)\n",
    "train_house_median = X_train['House_Size'].median()\n",
    "train_land_median = X_train['Land_Size'].median()\n",
    "\n",
    "X_train_filled = X_train.copy()\n",
    "X_test_filled = X_test.copy()\n",
    "\n",
    "X_train_filled['House_Size'].fillna(train_house_median, inplace=True)\n",
    "X_train_filled['Land_Size'].fillna(train_land_median, inplace=True)\n",
    "X_test_filled['House_Size'].fillna(train_house_median, inplace=True)\n",
    "X_test_filled['Land_Size'].fillna(train_land_median, inplace=True)\n",
    "\n",
    "print(f\"Imputed missing House_Size with: {train_house_median:.2f}\")\n",
    "print(f\"Imputed missing Land_Size with: {train_land_median:.2f}\")\n",
    "\n",
    "# Fit scaler ONLY on training data\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['Bedrooms', 'Bathrooms', 'House_Size', 'Land_Size']\n",
    "\n",
    "scaler.fit(X_train_filled[columns_to_scale])\n",
    "\n",
    "# Transform both train and test with the same scaler\n",
    "X_train_scaled = X_train_filled.copy()\n",
    "X_test_scaled = X_test_filled.copy()\n",
    "\n",
    "X_train_scaled[columns_to_scale] = scaler.transform(X_train_filled[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler.transform(X_test_filled[columns_to_scale])\n",
    "\n",
    "print(f\"\\nScaled features: {columns_to_scale}\")\n",
    "print(f\"\\nTraining set statistics (after scaling):\")\n",
    "for col in columns_to_scale:\n",
    "    print(f\"  {col}: Mean={X_train_scaled[col].mean():.2f}, Std={X_train_scaled[col].std():.2f}\")\n",
    "\n",
    "print(f\"\\nTest set statistics (after scaling):\")\n",
    "for col in columns_to_scale:\n",
    "    print(f\"  {col}: Mean={X_test_scaled[col].mean():.2f}, Std={X_test_scaled[col].std():.2f}\")\n",
    "\n",
    "print(f\"\\nTarget variable (Price_Log) statistics:\")\n",
    "print(f\"  Training: Mean={y_train.mean():.2f}, Std={y_train.std():.2f}, Skewness={y_train.skew():.2f}\")\n",
    "print(f\"  Test: Mean={y_test.mean():.2f}, Std={y_test.std():.2f}, Skewness={y_test.skew():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e6d88a",
   "metadata": {},
   "source": [
    "## Step 7: Correlation Analysis\n",
    "\n",
    "Analyze feature correlations to understand relationships and detect multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcef20be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Correlation Matrix:\n",
      "======================================================================\n",
      "              Bedrooms  Bathrooms  House_Size  Land_Size  Is_Brand_New  \\\n",
      "Bedrooms         1.000      0.607       0.614      0.315        -0.053   \n",
      "Bathrooms        0.607      1.000       0.667      0.162         0.042   \n",
      "House_Size       0.614      0.667       1.000      0.407        -0.039   \n",
      "Land_Size        0.315      0.162       0.407      1.000        -0.205   \n",
      "Is_Brand_New    -0.053      0.042      -0.039     -0.205         1.000   \n",
      "Is_Modern        0.071      0.218       0.216     -0.053         0.265   \n",
      "City_Tier       -0.310     -0.388      -0.458     -0.276         0.166   \n",
      "\n",
      "              Is_Modern  City_Tier  \n",
      "Bedrooms          0.071     -0.310  \n",
      "Bathrooms         0.218     -0.388  \n",
      "House_Size        0.216     -0.458  \n",
      "Land_Size        -0.053     -0.276  \n",
      "Is_Brand_New      0.265      0.166  \n",
      "Is_Modern         1.000     -0.105  \n",
      "City_Tier        -0.105      1.000  \n",
      "\n",
      "======================================================================\n",
      "Highly Correlated Feature Pairs (|correlation| > 0.7):\n",
      "======================================================================\n",
      "  No highly correlated pairs found. Features are relatively independent.\n",
      "\n",
      "======================================================================\n",
      "Feature Correlation with Target (Price_Log):\n",
      "======================================================================\n",
      "  House_Size: 0.735\n",
      "  Bathrooms: 0.628\n",
      "  Bedrooms: 0.504\n",
      "  Land_Size: 0.463\n",
      "  Is_Modern: 0.242\n",
      "  Is_Brand_New: -0.098\n",
      "  City_Tier: -0.688\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate correlation matrix on scaled training data\n",
    "correlation_matrix = X_train_scaled.corr()\n",
    "\n",
    "print(\"Feature Correlation Matrix:\")\n",
    "print(\"=\" * 70)\n",
    "print(correlation_matrix.round(3))\n",
    "\n",
    "# Identify highly correlated pairs (|corr| > 0.7)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Highly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "print(\"=\" * 70)\n",
    "high_corr_found = False\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            print(f\"  {correlation_matrix.columns[i]} <-> {correlation_matrix.columns[j]}: {corr_val:.3f}\")\n",
    "            high_corr_found = True\n",
    "\n",
    "if not high_corr_found:\n",
    "    print(\"  No highly correlated pairs found. Features are relatively independent.\")\n",
    "\n",
    "# Correlation with target\n",
    "train_data_with_target = X_train_scaled.copy()\n",
    "train_data_with_target['Price_Log'] = y_train.values\n",
    "\n",
    "target_correlation = train_data_with_target.corr()['Price_Log'].sort_values(ascending=False)\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Feature Correlation with Target (Price_Log):\")\n",
    "print(\"=\" * 70)\n",
    "for feature, corr in target_correlation.items():\n",
    "    if feature != 'Price_Log':\n",
    "        print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d72f4d",
   "metadata": {},
   "source": [
    "## Step 8: Prepare Final Datasets\n",
    "\n",
    "Combine features and target into final train/test datasets ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78dd227e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Dataset: 724 rows, 8 columns\n",
      "Final Test Dataset: 182 rows, 8 columns\n",
      "\n",
      "Final features:\n",
      "  - Bedrooms\n",
      "  - Bathrooms\n",
      "  - House_Size\n",
      "  - Land_Size\n",
      "  - Is_Brand_New\n",
      "  - Is_Modern\n",
      "  - City_Tier\n",
      "\n",
      "Target variable: Price_Log (log-transformed price)\n",
      "\n",
      "Training set summary:\n",
      "           Bedrooms     Bathrooms    House_Size     Land_Size  Is_Brand_New  \\\n",
      "count  7.240000e+02  7.240000e+02  7.240000e+02  7.240000e+02    724.000000   \n",
      "mean   6.869888e-17 -1.472119e-16 -8.342007e-17  2.441264e-16      0.209945   \n",
      "std    1.000691e+00  1.000691e+00  1.000691e+00  1.000691e+00      0.407550   \n",
      "min   -1.884979e+00 -1.926143e+00 -2.282153e+00 -2.003928e+00      0.000000   \n",
      "25%   -9.817861e-01 -1.044089e+00 -6.893001e-01 -7.178361e-01      0.000000   \n",
      "50%   -7.859279e-02 -1.620348e-01 -5.215899e-02 -2.401449e-01      0.000000   \n",
      "75%    8.246005e-01  7.200194e-01  5.053394e-01  3.477827e-01      0.000000   \n",
      "max    5.340567e+00  2.484128e+00  4.089258e+00  4.242803e+00      1.000000   \n",
      "\n",
      "        Is_Modern   City_Tier   Price_Log  \n",
      "count  724.000000  724.000000  724.000000  \n",
      "mean     0.424033    3.522099   17.691405  \n",
      "std      0.494537    1.441648    0.697849  \n",
      "min      0.000000    1.000000   14.220976  \n",
      "25%      0.000000    2.000000   17.229105  \n",
      "50%      0.000000    4.000000   17.599700  \n",
      "75%      1.000000    5.000000   18.064006  \n",
      "max      1.000000    6.000000   20.560747  \n",
      "\n",
      "Test set summary:\n",
      "         Bedrooms   Bathrooms  House_Size   Land_Size  Is_Brand_New  \\\n",
      "count  182.000000  182.000000  182.000000  182.000000    182.000000   \n",
      "mean    -0.073630   -0.050566   -0.120734    0.012420      0.159341   \n",
      "std      0.922924    0.913401    0.862560    1.056035      0.367003   \n",
      "min     -1.884979   -1.926143   -1.804297   -1.682405      0.000000   \n",
      "25%     -0.981786   -1.044089   -0.729121   -0.717836      0.000000   \n",
      "50%     -0.078593   -0.162035   -0.139766   -0.203399      0.000000   \n",
      "75%      0.824601    0.720019    0.306233    0.506248      0.000000   \n",
      "max      3.534180    2.484128    3.292832    4.059076      1.000000   \n",
      "\n",
      "        Is_Modern   City_Tier   Price_Log  \n",
      "count  182.000000  182.000000  182.000000  \n",
      "mean     0.384615    3.516484   17.649258  \n",
      "std      0.487846    1.447899    0.638840  \n",
      "min      0.000000    1.000000   16.166886  \n",
      "25%      0.000000    2.000000   17.169763  \n",
      "50%      0.000000    4.000000   17.588205  \n",
      "75%      1.000000    5.000000   18.056837  \n",
      "max      1.000000    6.000000   19.413933  \n"
     ]
    }
   ],
   "source": [
    "# Add target variable to create complete datasets\n",
    "train_data = X_train_scaled.copy()\n",
    "train_data['Price_Log'] = y_train.values\n",
    "\n",
    "test_data = X_test_scaled.copy()\n",
    "test_data['Price_Log'] = y_test.values\n",
    "\n",
    "print(f\"Final Training Dataset: {train_data.shape[0]} rows, {train_data.shape[1]} columns\")\n",
    "print(f\"Final Test Dataset: {test_data.shape[0]} rows, {test_data.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\nFinal features:\")\n",
    "for col in train_data.columns:\n",
    "    if col != 'Price_Log':\n",
    "        print(f\"  - {col}\")\n",
    "print(f\"\\nTarget variable: Price_Log (log-transformed price)\")\n",
    "\n",
    "print(f\"\\nTraining set summary:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "print(f\"\\nTest set summary:\")\n",
    "print(test_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655d208",
   "metadata": {},
   "source": [
    "## Save Processed Data & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17c33238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Training data saved to: ../data/03_processed/train_data.csv\n",
      "  Shape: 724 rows, 8 columns\n",
      "\n",
      "‚úì Test data saved to: ../data/03_processed/test_data.csv\n",
      "  Shape: 182 rows, 8 columns\n",
      "\n",
      "‚úì Preprocessing artifacts saved to: ../models/preprocessing_artifacts.pkl\n",
      "  Contains: scaler, imputation values, feature columns, city mappings\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "‚úì Training samples: 724\n",
      "‚úì Test samples: 182\n",
      "‚úì Features: 7\n",
      "‚úì Target: Price_Log (log-transformed price)\n",
      "‚úì All artifacts saved and ready for modeling!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('../data/03_processed', exist_ok=True)\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save training and test datasets\n",
    "train_path = '../data/03_processed/train_data.csv'\n",
    "test_path = '../data/03_processed/test_data.csv'\n",
    "\n",
    "train_data.to_csv(train_path, index=False)\n",
    "test_data.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"‚úì Training data saved to: {train_path}\")\n",
    "print(f\"  Shape: {train_data.shape[0]} rows, {train_data.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\n‚úì Test data saved to: {test_path}\")\n",
    "print(f\"  Shape: {test_data.shape[0]} rows, {test_data.shape[1]} columns\")\n",
    "\n",
    "# Save preprocessing artifacts for production use\n",
    "preprocessing_artifacts = {\n",
    "    'scaler': scaler,\n",
    "    'imputation_values': {\n",
    "        'House_Size_median': train_house_median,\n",
    "        'Land_Size_median': train_land_median\n",
    "    },\n",
    "    'feature_columns': columns_to_scale,\n",
    "    'tier_labels': tier_labels,\n",
    "    'city_tier_map': city_tier_map\n",
    "}\n",
    "\n",
    "artifacts_path = '../models/preprocessing_artifacts.pkl'\n",
    "joblib.dump(preprocessing_artifacts, artifacts_path)\n",
    "\n",
    "print(f\"\\n‚úì Preprocessing artifacts saved to: {artifacts_path}\")\n",
    "print(f\"  Contains: scaler, imputation values, feature columns, city mappings\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"‚úì Training samples: {len(train_data)}\")\n",
    "print(f\"‚úì Test samples: {len(test_data)}\")\n",
    "print(f\"‚úì Features: {len([col for col in train_data.columns if col != 'Price_Log'])}\")\n",
    "print(f\"‚úì Target: Price_Log (log-transformed price)\")\n",
    "print(f\"‚úì All artifacts saved and ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a906e",
   "metadata": {},
   "source": [
    "## Pipeline Summary\n",
    "\n",
    "**Data Quality Improvements:**\n",
    "- Missing value analysis and handling\n",
    "- Outlier removal using IQR method (3x multiplier)\n",
    "- Cleaned numeric fields (House_Size, Land_Size)\n",
    "- Comprehensive validation (bedrooms, bathrooms, price ranges)\n",
    "- Removed invalid/extreme entries\n",
    "\n",
    "**Feature Engineering:**\n",
    "- Extracted 2 binary features from descriptions (Is_Brand_New, Is_Modern)\n",
    "- Created City_Tier to reduce cardinality (6 tiers from Luxury to Budget)\n",
    "- Log-transformed Price to normalize distribution\n",
    "- Scaled all numeric features using StandardScaler\n",
    "\n",
    "**Best Practices Applied:**\n",
    "- ‚úÖ Train-Test split (80-20) BEFORE scaling to prevent data leakage\n",
    "- ‚úÖ Scaler fitted only on training data\n",
    "- ‚úÖ Stratified split to maintain City_Tier distribution\n",
    "- ‚úÖ Saved preprocessing artifacts for production deployment\n",
    "- ‚úÖ Correlation analysis to detect multicollinearity\n",
    "- ‚úÖ Comprehensive validation and quality checks\n",
    "\n",
    "**Output Files:**\n",
    "- `train_data.csv` - Training dataset ready for modeling\n",
    "- `test_data.csv` - Test dataset for final evaluation\n",
    "- `preprocessing_artifacts.pkl` - Scaler and mappings for production use\n",
    "\n",
    "**Ready for Modeling!** üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
